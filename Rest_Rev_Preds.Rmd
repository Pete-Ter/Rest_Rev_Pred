---
title: "Rest Rev Preds"
author: "Peter Terlecky"
date: "March 30, 2015"
output: html_document
---


```{r import data}
library(plyr); library(dplyr); library(Metrics); library(caret)
library(rpivotTable); library(gbm); library(randomForest); library(FactoMineR)
library(elasticnet);library(lars); library(caretEnsemble); library(glmnet)
```

```{r load data}
train <- read.csv('data/train.csv', header = T)
test <- read.csv('data/test.csv', header = T)
```

```{r}
summary(train)
str(train)
```

```{r graphs}
hist(train$revenue)
boxplot(train$revenue ~ train$City.gr)
boxplot(train$revenue ~ train$Type)
boxplot(train$revenue ~ train$City)
boxplot(train$revenue)
table(train$City)

plot(train$Open.days, train$revenue)
#cor(train$Open.days,train$revenue)
View(count(train, City))

plot(train$P3, train$revenue)

table(train$P2)

#P17 P2 P3 11 P18 36 37

#P17 -- 1
#P2  -- 2, 3
#P3 -- 5, 6
#P18 -- 4, 12
#P36 -- 3

train$P17.ind <- ifelse(train$P17==1,1,0)
train$P2.ind.2 <- ifelse(train$P2==2,1,0)
train$P2.ind.3 <- ifelse(train$P2==3,1,0)
train$P3.ind.5 <- ifelse(train$P3==5,1,0)
train$P3.ind.6 <- ifelse(train$P3==6,1,0)
train$P18.ind.4 <- ifelse(train$P18==4,1,0)
train$P18.ind.12<- ifelse(train$P18==12,1,0)
train$P36.ind.3 <- ifelse(train$P36==3,1,0)


test$P17.ind <- ifelse(test$P17==1,1,0)
test$P2.ind.2 <- ifelse(test$P2==2,1,0)
test$P2.ind.3 <- ifelse(test$P2==3,1,0)
test$P3.ind.5 <- ifelse(test$P3==5,1,0)
test$P3.ind.6 <- ifelse(test$P3==6,1,0)
test$P18.ind.4 <- ifelse(test$P18==4,1,0)
test$P18.ind.12<- ifelse(test$P18==12,1,0)
test$P36.ind.3 <- ifelse(test$P36==3,1,0)

train <- select(train, Type, Open.days, City.Group, revenue, P2.ind.2, P2.ind.3, P3.ind.6, P3.ind.5, P17.ind, P18.ind.4, P18.ind.12, P36.ind.3, P11, P36, P2, P3, P17, P18)

```

```{r preProcessing}
id <- train$Id
train$Id <- NULL
train$Open.Date <- as.Date(train$Open.Date, format = "%m/%d/%Y")
#train$Open.yr <- as.factor(format(train$Open.Date, "%Y")) 
train$Open.days <- as.numeric(as.Date("2015-01-01")-train$Open.Date)
#Open.Date <- train$Open.Date
train$Open.Date <- NULL

test$Open.Date <- as.Date(test$Open.Date, format = "%m/%d/%Y")
#test$Open.yr <- as.factor(format(test$Open.Date, "%Y")) 
test$Open.days <- as.numeric(as.Date("2015-01-01")-test$Open.Date)
summary(test$Open.days)

#train$Open.days <- NULL

summary(lm(revenue ~ Open.days, data=train))
cor(train$Open.days, train$revenue)

#train$City.gr <- as.factor(ifelse(train$City %in% "Ä°stanbul", "Ä°stanbul", ifelse(train$City %in% "Ankara", "Ankara", as.character(train$City.Group))))

#levels(train$City.gr)[levels(train$City.gr)=="Big Cities"] <- "Ankara"

test$City.gr <- as.factor(ifelse(test$City %in% "Ä°stanbul", "Ä°stanbul", ifelse(test$City %in% "Ankara", "Ankara", as.character(test$City.Group))))

#levels(test$City.gr)[levels(test$City.gr)=="Big Cities"] <- "Ankara"


#train$Ank.Ind <- as.factor(ifelse(train$City=="Ankara", 1, 0))
#train$Ist.Ind <- as.factor(ifelse(train$City=="Ä°stanbul", 1, 0))
#test$Ank.Ind <- as.factor(ifelse(test$City=="Ankara", 1, 0))
#test$Ist.Ind <- as.factor(ifelse(test$City=="Ä°stanbul", 1, 0))
#train$Ism.Ind <- as.factor(ifelse(train$City=="Ä°zmir", 1, 0))
#test$Ism.Ind <- as.factor(ifelse(test$City=="Ä°zmir", 1, 0))
#train$Samsun.Ind <- as.factor(ifelse(train$City=="Samsun", 1, 0))
#test$Samsun.Ind <- as.factor(ifelse(test$City=="Samsun", 1, 0))

train$City <- NULL
#train$City.Group <- NULL

num.predictors <- ncol(train) - 1

#levels(train$Type)[levels(train$Type)=="DT"] <- "FC"
#levels(test$Type)[levels(test$Type)=="DT"] <- "FC"
levels(test$Type)[levels(test$Type)=="MB"] <- "IL"

#train$revenue[train$revenue>.85e7] <- .85e7
#train$revenue[train$revenue< 1750000] <- 1750000

train$revenue[train$revenue>.9e7] <- .9e7

rpivotTable(train)
```

```{r recursive random forest feature elim}
train$P9 <- NULL
train$P12 <- NULL
train$P3 <- NULL
train$P35 <- NULL
train$P33 <- NULL
train$P8 <- NULL
train$P30 <- NULL
train$P24 <- NULL
train$P15 <- NULL
train$P21 <- NULL
train$P11 <- NULL
train$P7 <- NULL
train$P22 <- NULL
train$P10 <- NULL
train$P19 <- NULL
train$P27 <- NULL
train$P37 <- NULL
train$P13 <- NULL
train$P34 <- NULL
train$P26 <- NULL
train$P31 <- NULL
#train$type.city_revenueRate <- NULL
#train$P28 <- NULL
cor(as.numeric(train$P28),train$revenue)
train$P32 <- NULL
train$P29 <- NULL
####
train$P18 <- NULL
#
train$P14 <- NULL
#train$P16 <- NULL

#train <- select(train,Type, Open.days, City.gr, revenue, P1, P2, P6, P17, P28, P36)
```


```{r removing vars}
train$P3 <- NULL
train$P12 <- NULL
train$P15 <- NULL
train$P11 <- NULL
train$P24 <- NULL

```

```{r vars to keep}

#train <- select(train, Open.days, City.gr, revenue, P1, P2, P6, P28, P29, P36)

#P17 P2 P3 11 P18 36 37
train <- select(train, Open.days, City.gr, revenue, P2, P3, P11, P17, P18, P36, P37)
#train$P2 <- as.factor(train$P2)
#test$P2 <- as.factor(test$P2)
#train$P3 <- as.factor(train$P3)
#test$P3 <- as.factor(test$P3)
train$P11 <- as.factor(train$P11)
test$P11 <- as.factor(test$P11)
#train$P17 <- as.factor(train$P17)
#test$P17 <- as.factor(test$P17)
#train$P18 <- as.factor(train$P18)
#test$P18 <- as.factor(test$P18)
#train$P36 <- as.factor(train$P36)
#test$P36 <- as.factor(test$P36)
train$P37 <- as.factor(train$P37)
test$P37 <- as.factor(test$P37)

train$Open.days.log <- log(train$Open.days)
test$Open.days.log <- log(test$Open.days)

train$revenue.log <- log(train$revenue)
test$revenue.log <- log(test$revenue)

train$P2.log <- log(train$P2+1)
test$P2.log <- log(test$P2+1)

train$P3.log <- log(train$P3+1)
test$P3.log <- log(test$P3+1)

train$P17.log <- log(train$P17+1)
test$P17.log <- log(test$P17+1)

train$Open.days <- NULL
train$revenue <- NULL
train$P2 <- NULL
train$P3 <- NULL
train$P17 <- NULL

table(train$P2)
table(test$P2)



```


```{r new var creation}
train$type.city <- paste0(train$Type,"_",train$City.gr)
table(train$type.city)
test$type.city <- paste0(test$Type,"_",test$City.gr)

train <- getOneWayVars(train,test,c("type.city"),"revenue",freq=F, rand=1)
summary(train)
train$type.city <- NULL
```


```{r PCA}

pca <- PCA(select(train,starts_with("P")), graph=T)
pca$eig

trans <- preProcess(select(train, starts_with("P")),method=c("center", "scale", "pca"), thresh = 0.90)
transformed <- predict(trans, select(train, starts_with("P")))
head(transformed)

test.transformed <- predict(trans, newdata=select(test, starts_with("P")))

head(test.transformed)

train.pca <- cbind(select(train, -starts_with("P")), transformed)
test.pca <- cbind(test, test.transformed)
```


```{r formulas}
rf.form <- revenue ~ .
pls.form <- revenue.log ~ .

```


```{r caret fitcontrol}
fitControl <- trainControl(## 4-fold CV
                           method = "repeatedcv",
                           number = 5,
                           ## repeated ten times
                           repeats = 10)

```


```{r rf}
rFGrid <-  expand.grid(mtry=1:20, maxnodes=seq(4,14), nodesize=seq(5, 15), 
                       ntree=c(500, 1000))

set.seed(6)
rfFit <- train(as.formula(rf.form),
               data=train,
               method="rf",
               trControl=fitControl,
               metric="RMSE",
               verbose=T,
               tuneGrid=rFGrid, 
               importance=T#,
               #ntree=500
               )
rfFit

ImpMeasure<-data.frame(varImp(rfFit)$importance)
    ImpMeasure$Vars<-row.names(ImpMeasure)
ImpMeasure[order(-ImpMeasure$Overall),]
```


```{r rF pred}
test$Prediction <- predict(rfFit, newdata=test)
```


```{r rF PCA}

rFGrid <-  expand.grid(.mtry=1:9)

set.seed(6)
rfFit <- train(as.formula(rf.form),
               data=train.pca,
               method="rf",
               trControl=fitControl,
               metric="RMSE",
               verbose=T,
               tuneGrid=rFGrid, 
               importance=T
               #ntree=1600
               )
rfFit

varImp(rfFit, scale=T)
```

```{r PLS}

plsFit <- train(as.formula(pls.form),
               data=train,
               method="pls",
               trControl=fitControl,
               metric="RMSE",
               tuneLength=20,
               preProc=c("center","scale")
               )
plsFit

predict(plsFit,newdata=test)

```

```{r glmnet}

enetGrid <- expand.grid(.lambda = c(0,0.001, 0.01, .1),
 .alpha = seq(.005, 1, length = 200))

set.seed(100)
enetTune <- train(as.formula(pls.form),
   data=train,
   method = "glmnet",
   tuneGrid = enetGrid,
   trControl = fitControl,
   preProc = c("center", "scale"))

enetTune
plot(enetTune)

test$Prediction <- predict(enetTune, newdata=test)

```

```{r lasso}

lassoGrid <- expand.grid(.fraction = seq(.0005, .05, length = 1000))

set.seed(100)
lassoTune <- train(as.formula(pls.form),
   data=train,
   method = "lasso",
   tuneGrid = lassoGrid,
   trControl = fitControl,
   preProc = c("center", "scale"))

lassoTune

plot(lassoTune)
```

```{r ridge}

ridgeGrid <- expand.grid(.lambda = c(0,0.001, 0.01, .1, .5, .6, .9))

set.seed(100)
ridgeTune <- train(as.formula(pls.form),
   data=train,
   method = "ridge",
   tuneGrid = ridgeGrid,
   trControl = fitControl,
   preProc = c("center", "scale"))

ridgeTune

plot(ridgeTune)
```


```{r caretEnsemble}

#model_list <- caretList(
#  as.formula(rf.form), data=train,
#  trControl=fitControl,
#  methodList=c('rf', 'lasso')
#  )

model_list <- caretList(
  as.formula(rf.form), data=train,
  trControl=fitControl,
  metric='RMSE',
  #methodList=c('rf', 'lasso'),
  tuneList=list(
    rf=caretModelSpec(method='rf', tuneGrid=data.frame(.mtry=1:18)),
    lasso=caretModelSpec(method='lasso', tuneGrid=expand.grid(.fraction = seq(.0005, .05, length = 1000)), preProc = c("center", "scale"))
  ))

xyplot(resamples(model_list))
modelCor(resamples(model_list))

greedy_ensemble <- caretEnsemble(model_list)
summary(greedy_ensemble)
varImp(greedy_ensemble)

test$Prediction <- predict(greedy_ensemble, newdata=test)
```


```{r cor}
apply(cor(select(train, starts_with("P")))-diag(ncol(select(train, starts_with("P")))), 2, max)

apply(cor(select(train, starts_with("P")))-diag(ncol(select(train, starts_with("P")))), 2, mean)

cor(cbind(select(train,starts_with("P")), select(train, revenue)))

train$P36 <- NULL
dtrain$P9 <- NULL
train$P10 <- NULL
train$P26 <- NULL
train$P16 <- NULL
train$P25 <- NULL
train$P32 <- NULL
train$P34 <- NULL
train$P18 <- NULL
train$P13 <- NULL
train$P14 <- NULL

```

```{r Nulling P's}
train$P37 <- NULL
train$P3 <- NULL
train$P33 <- NULL
train$P16 <- NULL
train$P15 <- NULL
train$P14 <- NULL
####
train$P4 <- NULL
train$P7 <- NULL
train$P8 <- NULL
train$P9 <- NULL
####
train$P10 <- NULL
train$P11 <- NULL
train$P12 <- NULL
train$P19 <- NULL
###########
train$P22 <- NULL
train$P24 <- NULL

```

```{r runRF}
rFGrid <-  expand.grid(mtry=2:5, maxnodes=seq(5,14), nodesize=seq(6,12), 
                       ntree=c(75, 200, 500, 1000))


############################################################################################################
# Function to run Random Forest model
runRF <- function(train, test, model, response, trees, mtry, maxnodes, nodesize, set.test=F) {
  
    set.seed(2)
  
  rfModel <- randomForest(formula = model,
                          data = train,
                          ntree = trees, # Should not be set to too small to ensure that every input row gets predicted at least a few times
                          mtry = mtry,  # Number of variables randomly sampled as candidates at each split
                          maxnodes = maxnodes, # Maximum number of terminal nodes trees can have. If not given, trees are grown to the maximum possible (subject to limits by nodesize)
                          nodesize = nodesize, # Minimum size of terminal nodes. Setting this number larger causes smaller trees
                                               # to be grown (and thus take less time).Default=1 (for classification); Default=5 (for regression)
                          importance = TRUE,
                          proximity = TRUE
                          )
  
  # Score
  #train$score_rf <- predict(rfModel, train, type='response')
  test$score_rf <- predict(rfModel, test, type='response')
  
  if(set.test==F){
    rmse <- caret::RMSE(test$score_rf, test[, response])
    mae <- mae(test[, response], test$score_rf)
  }else
    test.pr <<- test
  return(rmse)
}

```

```{r crossval}
mean.met <- CrossVal(train, 'revenue', as.formula(rf.form), 5, 2, rFGrid)

rFGrid[which.min(mean.met), ]

mean.met[which.min(mean.met)]

runRF(train, test, as.formula(rf.form), 'revenue', rFGrid$ntree[which.min(mean.met)],  rFGrid$mtry[which.min(mean.met)],rFGrid$maxnodes[which.min(mean.met)],rFGrid$nodesize[which.min(mean.met)], set.test=T)

test <- test.pr
test$Prediction <- test$score_rf
test$Prediction
```


```{r CrossVal}


CrossVal <- function(data, y, mod, folds, number, params){
  "y is the string name of the response"
  "params is the data.frame of parameters"
  "mod is formula already in formula form"
  set.seed(4)
  
  idx <- createMultiFolds(data[, y], k=folds, times=number)
  #idx <- createFolds(data[, y], k=folds)
  
  mean.metric <- rep(0, nrow(params))
  
  for(j in 1:nrow(params)){
    
    rmse <- rep(0, folds*number)

    for(i in 1:(folds*number)){
    
      train <- data[idx[[i]], ]
      test <- data[-idx[[i]], ]
    
      rmse[i] <- runRF(train, test, mod, y, params$ntree[j],
                        params$mtry[j], params$maxnodes[j], params$nodesize[j])
    
    }
    mean.metric[j] <- mean(rmse)
  }
  return(mean.metric)
}
```

```{r getOneWay}

############################################################################################################
# Get count and avg responses for factor variables (a.ka. Leave one-out experience variables)
getOneWayVars <- function(train, test, varList, yvar, freq=TRUE, cred=0, rand=0) {
  # freq=TRUE when you want the factor counts; set cred > 0 for credibility adjustment; rand > 0 for random shocking
  # Requires dplyr
  
  len <- length(varList)
  rowNumCheck.train <- nrow(train)
  rowNumCheck.test <- nrow(test)
  
  train$responseVar <- train[, yvar]
  total_avg_response <- mean(train$responseVar, na.rm=TRUE)  # Fixed only for this contest
  
  for (i in 1:len) {
    train$groupingVar <- train[, varList[i]]
    test$groupingVar <- test[, varList[i]]   
    
    df <- train %>%
      group_by(groupingVar) %>%
      summarise(
        freq = n() - 1,
        YRate = mean(responseVar, na.rm=TRUE)
      ) %>% ungroup()
    
    train <- left_join(train, df, by='groupingVar')
    
    train_tmp <- unique(train[, c('groupingVar', 'freq', 'YRate')])
    test <- left_join(test, train_tmp, by='groupingVar')
    names(test)[which(names(test)=='freq')] <- 'dummyFreq'
    names(test)[which(names(test)=='YRate')] <- 'dummyRate'
    test$dummyFreq <- test$dummyFreq + 1
    test$dummyFreq[is.na(test$dummyFreq)] <- 0
    
    ids <- which(is.na(test$dummyRate))
    test$dummyRate[ids] <- total_avg_response
    test$dummyRate[-ids] <- (test$dummyRate[-ids] + (total_avg_response * cred / test$dummyFreq[-ids])) * (test$dummyFreq[-ids] / (test$dummyFreq[-ids] + cred))
    
    if (freq) {
      names(test)[which(names(test)=='dummyFreq')] <- paste(varList[i], '_freq', sep='')  
    } else {
      id <- which(names(test)=='dummyFreq')
      test[, id] <- NULL
    }
    
    names(test)[which(names(test)=='dummyRate')] <- paste(varList[i], '_', yvar, 'Rate', sep='')
    
    # Leave one out adjustment for train data
    train$YRate <- (train$YRate - (train$responseVar / (train$freq+1))) * (train$freq+1)/(train$freq)
    train$YRate <- (train$YRate + (total_avg_response * cred / train$freq)) * (train$freq / (train$freq + cred))
    train$YRate[train$freq == 0] <- total_avg_response
    set.seed(10)
    train$YRate <- train$YRate * (1+(runif(nrow(train))-0.5) * rand)
    
    if (freq) {
      names(train)[which(names(train)=='freq')] <- paste(varList[i], '_freq', sep='')
    } else {
      id <- which(names(train)=='freq')
      train[, id] <- NULL
    }
    
    names(train)[which(names(train)=='YRate')] <- paste(varList[i], '_', yvar, 'Rate', sep='')
    
    train$groupingVar <- NULL;
    test$groupingVar <- NULL;
  }
  
  train$responseVar <- NULL; train$groupingVar <- NULL; test$groupingVar <- NULL;
  
  if(nrow(train) != rowNumCheck.train) print('Error: Different number of rows in train data. Bad join!')
  
  if(nrow(test) != rowNumCheck.test) print('Error: Different number of rows in test data. Bad join!')
  
  test <<- test
  return(train)
}

################################################################################

getOneWayVars_retTest <- function(train, test, varList, yvar, freq=TRUE, cred=0, rand=0) {
  # freq=TRUE when you want the factor counts; set cred > 0 for credibility adjustment; rand > 0 for random shocking
  # Requires dplyr
  
  len <- length(varList)
  rowNumCheck.train <- nrow(train)
  rowNumCheck.test <- nrow(test)
  
  train$responseVar <- train[, yvar]
  total_avg_response <- mean(train$responseVar, na.rm=TRUE)  # Fixed only for this contest
  
  for (i in 1:len) {
    train$groupingVar <- train[, varList[i]]
    test$groupingVar <- test[, varList[i]]   
    
    df <- train %>%
      group_by(groupingVar) %>%
      summarise(
        freq = n() - 1,
        YRate = mean(responseVar, na.rm=TRUE)
      ) %>% ungroup()
    
    train <- left_join(train, df, by='groupingVar')
    
    train_tmp <- unique(train[, c('groupingVar', 'freq', 'YRate')])
    test <- left_join(test, train_tmp, by='groupingVar')
    names(test)[which(names(test)=='freq')] <- 'dummyFreq'
    names(test)[which(names(test)=='YRate')] <- 'dummyRate'
    test$dummyFreq <- test$dummyFreq + 1
    test$dummyFreq[is.na(test$dummyFreq)] <- 0
    
    ids <- which(is.na(test$dummyRate))
    test$dummyRate[ids] <- total_avg_response
    test$dummyRate[-ids] <- (test$dummyRate[-ids] + (total_avg_response * cred / test$dummyFreq[-ids])) * (test$dummyFreq[-ids] / (test$dummyFreq[-ids] + cred))
    
    if (freq) {
      names(test)[which(names(test)=='dummyFreq')] <- paste(varList[i], '_freq', sep='')  
    } else {
      id <- which(names(test)=='dummyFreq')
      test[, id] <- NULL
    }
    
    names(test)[which(names(test)=='dummyRate')] <- paste(varList[i], '_', yvar, 'Rate', sep='')
    
    # Leave one out adjustment for train data
    train$YRate <- (train$YRate - (train$responseVar / (train$freq+1))) * (train$freq+1)/(train$freq)
    train$YRate <- (train$YRate + (total_avg_response * cred / train$freq)) * (train$freq / (train$freq + cred))
    train$YRate[train$freq == 0] <- total_avg_response
    set.seed(10)
    train$YRate <- train$YRate * (1+(runif(nrow(train))-0.5) * rand)
    
    if (freq) {
      names(train)[which(names(train)=='freq')] <- paste(varList[i], '_freq', sep='')
    } else {
      id <- which(names(train)=='freq')
      train[, id] <- NULL
    }
    
    names(train)[which(names(train)=='YRate')] <- paste(varList[i], '_', yvar, 'Rate', sep='')
    
    train$groupingVar <- NULL;
    test$groupingVar <- NULL;
  }
  
  train$responseVar <- NULL; train$groupingVar <- NULL; test$groupingVar <- NULL;
  
  if(nrow(train) != rowNumCheck.train) print('Error: Different number of rows in train data. Bad join!')
  
  if(nrow(test) != rowNumCheck.test) print('Error: Different number of rows in test data. Bad join!')
  
  return(test)
}


```



```{r csv file}
write.csv(select(test, Id, Prediction), "preds.csv", row.names = F)

```


