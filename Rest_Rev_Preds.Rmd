---
title: "Rest Rev Preds"
author: "Peter Terlecky"
date: "March 30, 2015"
output: html_document
---


```{r import data}
library(plyr); library(dplyr); library(Metrics); library(caret)
library(rpivotTable); library(gbm); library(randomForest); library(FactoMineR)
library(elasticnet);library(lars); library(caretEnsemble); library(glmnet)
```

```{r load data}
train <- read.csv('data/train.csv', header = T)
test <- read.csv('data/test.csv', header = T)
```

```{r}
summary(train)
str(train)
```

```{r graphs}
hist(train$revenue)
boxplot(train$revenue ~ train$City.Group)
boxplot(train$revenue ~ train$Type)
boxplot(train$revenue ~ train$City)
boxplot(train$revenue)

#cor(train$Open.days,train$revenue)
View(count(train, City))
```

```{r preProcessing}
id <- train$Id
train$Id <- NULL
train$Open.Date <- as.Date(train$Open.Date, format = "%m/%d/%Y")
#train$Open.yr <- as.factor(format(train$Open.Date, "%Y")) 
train$Open.days <- as.numeric(as.Date("2015-01-01")-train$Open.Date)
#Open.Date <- train$Open.Date
train$Open.Date <- NULL

test$Open.Date <- as.Date(test$Open.Date, format = "%m/%d/%Y")
#test$Open.yr <- as.factor(format(test$Open.Date, "%Y")) 
test$Open.days <- as.numeric(as.Date("2015-01-01")-test$Open.Date)
summary(test$Open.days)

#train$Open.days <- NULL

summary(lm(revenue ~ Open.days, data=train))
cor(train$Open.days, train$revenue)

train$City.gr <- as.factor(ifelse(train$City %in% "Ä°stanbul", "Ä°stanbul", ifelse(train$City %in% "Ankara", "Ankara", as.character(train$City.Group))))

levels(train$City.gr)[levels(train$City.gr)=="Big Cities"] <- "Ankara"

test$City.gr <- as.factor(ifelse(test$City %in% "Ä°stanbul", "Ä°stanbul", ifelse(test$City %in% "Ankara", "Ankara", as.character(test$City.Group))))

levels(test$City.gr)[levels(test$City.gr)=="Big Cities"] <- "Ankara"


#train$Ank.Ind <- as.factor(ifelse(train$City=="Ankara", 1, 0))
#train$Ist.Ind <- as.factor(ifelse(train$City=="Ä°stanbul", 1, 0))
#test$Ank.Ind <- as.factor(ifelse(test$City=="Ankara", 1, 0))
#test$Ist.Ind <- as.factor(ifelse(test$City=="Ä°stanbul", 1, 0))
#train$Ism.Ind <- as.factor(ifelse(train$City=="Ä°zmir", 1, 0))
#test$Ism.Ind <- as.factor(ifelse(test$City=="Ä°zmir", 1, 0))
#train$Samsun.Ind <- as.factor(ifelse(train$City=="Samsun", 1, 0))
#test$Samsun.Ind <- as.factor(ifelse(test$City=="Samsun", 1, 0))

train$City <- NULL
train$City.Group <- NULL

num.predictors <- ncol(train) - 1

levels(train$Type)[levels(train$Type)=="DT"] <- "FC"
levels(test$Type)[levels(test$Type)=="DT"] <- "FC"
levels(test$Type)[levels(test$Type)=="MB"] <- "IL"

#train$revenue[train$revenue>.85e7] <- .85e7
#train$revenue[train$revenue< 1750000] <- 1750000

#train$revenue[train$revenue>.9e7] <- .9e7

rpivotTable(train)
```

```{r recursive random forest feature elim}
train$P9 <- NULL
train$P12 <- NULL
train$P3 <- NULL
train$P35 <- NULL
train$P33 <- NULL
train$P8 <- NULL
train$P30 <- NULL
train$P24 <- NULL
train$P15 <- NULL
train$P21 <- NULL
train$P11 <- NULL
train$P7 <- NULL
train$P22 <- NULL
train$P10 <- NULL
train$P19 <- NULL
train$P27 <- NULL
train$P37 <- NULL
train$P13 <- NULL
train$P34 <- NULL
train$P26 <- NULL
train$P31 <- NULL
#train$type.city_revenueRate <- NULL
#train$P28 <- NULL
cor(as.numeric(train$P28),train$revenue)
train$P32 <- NULL
train$P29 <- NULL
####
train$P18 <- NULL
#
train$P14 <- NULL
#train$P16 <- NULL

#train <- select(train,Type, Open.days, City.gr, revenue, P1, P2, P6, P17, P28, P36)
```


```{r removing vars}
train$P3 <- NULL
train$P12 <- NULL
train$P15 <- NULL
train$P11 <- NULL
train$P24 <- NULL

```

```{r new var creation}
train$type.city <- paste0(train$Type,"_",train$City.gr)
table(train$type.city)
test$type.city <- paste0(test$Type,"_",test$City.gr)

train <- getOneWayVars(train,test,c("type.city"),"revenue",freq=F, rand=1)
summary(train)
train$type.city <- NULL
```


```{r PCA}

pca <- PCA(select(train,starts_with("P")), graph=T)
pca$eig

trans <- preProcess(select(train, starts_with("P")),method=c("center", "scale", "pca"), thresh = 0.90)
transformed <- predict(trans, select(train, starts_with("P")))
head(transformed)

test.transformed <- predict(trans, newdata=select(test, starts_with("P")))

head(test.transformed)

train.pca <- cbind(select(train, -starts_with("P")), transformed)
test.pca <- cbind(test, test.transformed)
```


```{r formulas}
rf.form <- revenue ~ .
pls.form <- revenue ~ .

```


```{r caret fitcontrol}
fitControl <- trainControl(## 4-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)

```


```{r rf}
rFGrid <-  expand.grid(.mtry=1:11)

set.seed(6)
rfFit <- train(as.formula(rf.form),
               data=train,
               method="rf",
               trControl=fitControl,
               metric="RMSE",
               verbose=T,
               tuneGrid=rFGrid, 
               importance=T,
               ntree=500
               )
rfFit

ImpMeasure<-data.frame(varImp(rfFit)$importance)
    ImpMeasure$Vars<-row.names(ImpMeasure)
ImpMeasure[order(-ImpMeasure$Overall),]
```


```{r rF pred}
test$Prediction <- predict(rfFit, newdata=test)
```


```{r rF PCA}

rFGrid <-  expand.grid(.mtry=1:9)

set.seed(6)
rfFit <- train(as.formula(rf.form),
               data=train.pca,
               method="rf",
               trControl=fitControl,
               metric="RMSE",
               verbose=T,
               tuneGrid=rFGrid, 
               importance=T
               #ntree=1600
               )
rfFit

varImp(rfFit, scale=T)
```

```{r PLS}

plsFit <- train(as.formula(pls.form),
               data=train,
               method="pls",
               trControl=fitControl,
               metric="RMSE",
               tuneLength=20,
               preProc=c("center","scale")
               )
plsFit

predict(plsFit,newdata=test)

```

```{r glmnet}

enetGrid <- expand.grid(.lambda = c(0,0.001, 0.01, .1),
 .alpha = seq(.005, 1, length = 200))

set.seed(100)
enetTune <- train(as.formula(pls.form),
   data=train,
   method = "glmnet",
   tuneGrid = enetGrid,
   trControl = fitControl,
   preProc = c("center", "scale"))

enetTune
plot(enetTune)

test$Prediction <- predict(enetTune, newdata=test)

```

```{r lasso}

lassoGrid <- expand.grid(.fraction = seq(.0005, .05, length = 1000))

set.seed(100)
lassoTune <- train(as.formula(pls.form),
   data=train,
   method = "lasso",
   tuneGrid = lassoGrid,
   trControl = fitControl,
   preProc = c("center", "scale"))

lassoTune

plot(lassoTune)
```

```{r ridge}

ridgeGrid <- expand.grid(.lambda = c(0,0.001, 0.01, .1, .5, .6, .9))

set.seed(100)
ridgeTune <- train(as.formula(pls.form),
   data=train,
   method = "ridge",
   tuneGrid = ridgeGrid,
   trControl = fitControl,
   preProc = c("center", "scale"))

ridgeTune

plot(ridgeTune)
```


```{r caretEnsemble}

#model_list <- caretList(
#  as.formula(rf.form), data=train,
#  trControl=fitControl,
#  methodList=c('rf', 'lasso')
#  )

model_list <- caretList(
  as.formula(rf.form), data=train,
  trControl=fitControl,
  metric='RMSE',
  #methodList=c('rf', 'lasso'),
  tuneList=list(
    rf=caretModelSpec(method='rf', tuneGrid=data.frame(.mtry=1:18)),
    lasso=caretModelSpec(method='lasso', tuneGrid=expand.grid(.fraction = seq(.0005, .05, length = 1000)), preProc = c("center", "scale"))
  ))

xyplot(resamples(model_list))
modelCor(resamples(model_list))

greedy_ensemble <- caretEnsemble(model_list)
summary(greedy_ensemble)
varImp(greedy_ensemble)

test$Prediction <- predict(greedy_ensemble, newdata=test)
```


```{r cor}
apply(cor(select(train, starts_with("P")))-diag(ncol(select(train, starts_with("P")))), 2, max)

apply(cor(select(train, starts_with("P")))-diag(ncol(select(train, starts_with("P")))), 2, mean)

cor(cbind(select(train,starts_with("P")), select(train, revenue)))

train$P36 <- NULL
dtrain$P9 <- NULL
train$P10 <- NULL
train$P26 <- NULL
train$P16 <- NULL
train$P25 <- NULL
train$P32 <- NULL
train$P34 <- NULL
train$P18 <- NULL
train$P13 <- NULL
train$P14 <- NULL

```

```{r Nulling P's}
train$P37 <- NULL
train$P3 <- NULL
train$P33 <- NULL
train$P16 <- NULL
train$P15 <- NULL
train$P14 <- NULL
####
train$P4 <- NULL
train$P7 <- NULL
train$P8 <- NULL
train$P9 <- NULL
####
train$P10 <- NULL
train$P11 <- NULL
train$P12 <- NULL
train$P19 <- NULL
###########
train$P22 <- NULL
train$P24 <- NULL

```


```{r CrossVal}

CrossVal <- function(data, y, mod, folds, number){
  "y is the string name of the response"
  set.seed(4)
  
  idx <- createMultiFolds(data[, y], k=folds, times=number)
  #idx <- createFolds(data[, y], k=folds)
  
  rmse <- rep(0, folds*number)
  
  for(i in 1:(folds*number)){
    
    train <- data[idx[[i]], ]
    test<- data[-idx[[i]], ]
    
    #d <-trans(train, test)
    #train <- d$tr
    #test <- d$tst
    if(mod=='GBM')
      res <- GBoost(train, test)
    else if(mod=='ZIP')
      res <- ZIP(train, test)
    
    rmse[i] <- res$rmse

  }
  return(rmse=rmse)
}
```

```{r getOneWay}


############################################################################################################
# Get count and avg responses for factor variables (a.ka. Leave one-out experience variables)
getOneWayVars <- function(train, test, varList, yvar, freq=TRUE, cred=0, rand=0) {
  # freq=TRUE when you want the factor counts; set cred > 0 for credibility adjustment; rand > 0 for random shocking
  # Requires dplyr
  
  len <- length(varList)
  rowNumCheck.train <- nrow(train)
  rowNumCheck.test <- nrow(test)
  
  train$responseVar <- train[, yvar]
  total_avg_response <- mean(train$responseVar, na.rm=TRUE)  # Fixed only for this contest
  
  for (i in 1:len) {
    train$groupingVar <- train[, varList[i]]
    test$groupingVar <- test[, varList[i]]   
    
    df <- train %>%
      group_by(groupingVar) %>%
      summarise(
        freq = n() - 1,
        YRate = mean(responseVar, na.rm=TRUE)
      ) %>% ungroup()
    
    train <- left_join(train, df, by='groupingVar')
    
    train_tmp <- unique(train[, c('groupingVar', 'freq', 'YRate')])
    test <- left_join(test, train_tmp, by='groupingVar')
    names(test)[which(names(test)=='freq')] <- 'dummyFreq'
    names(test)[which(names(test)=='YRate')] <- 'dummyRate'
    test$dummyFreq <- test$dummyFreq + 1
    test$dummyFreq[is.na(test$dummyFreq)] <- 0
    
    ids <- which(is.na(test$dummyRate))
    test$dummyRate[ids] <- total_avg_response
    test$dummyRate[-ids] <- (test$dummyRate[-ids] + (total_avg_response * cred / test$dummyFreq[-ids])) * (test$dummyFreq[-ids] / (test$dummyFreq[-ids] + cred))
    
    if (freq) {
      names(test)[which(names(test)=='dummyFreq')] <- paste(varList[i], '_freq', sep='')  
    } else {
      id <- which(names(test)=='dummyFreq')
      test[, id] <- NULL
    }
    
    names(test)[which(names(test)=='dummyRate')] <- paste(varList[i], '_', yvar, 'Rate', sep='')
    
    # Leave one out adjustment for train data
    train$YRate <- (train$YRate - (train$responseVar / (train$freq+1))) * (train$freq+1)/(train$freq)
    train$YRate <- (train$YRate + (total_avg_response * cred / train$freq)) * (train$freq / (train$freq + cred))
    train$YRate[train$freq == 0] <- total_avg_response
    set.seed(10)
    train$YRate <- train$YRate * (1+(runif(nrow(train))-0.5) * rand)
    
    if (freq) {
      names(train)[which(names(train)=='freq')] <- paste(varList[i], '_freq', sep='')
    } else {
      id <- which(names(train)=='freq')
      train[, id] <- NULL
    }
    
    names(train)[which(names(train)=='YRate')] <- paste(varList[i], '_', yvar, 'Rate', sep='')
    
    train$groupingVar <- NULL;
    test$groupingVar <- NULL;
  }
  
  train$responseVar <- NULL; train$groupingVar <- NULL; test$groupingVar <- NULL;
  
  if(nrow(train) != rowNumCheck.train) print('Error: Different number of rows in train data. Bad join!')
  
  if(nrow(test) != rowNumCheck.test) print('Error: Different number of rows in test data. Bad join!')
  
  test <<- test
  return(train)
}

################################################################################

getOneWayVars_retTest <- function(train, test, varList, yvar, freq=TRUE, cred=0, rand=0) {
  # freq=TRUE when you want the factor counts; set cred > 0 for credibility adjustment; rand > 0 for random shocking
  # Requires dplyr
  
  len <- length(varList)
  rowNumCheck.train <- nrow(train)
  rowNumCheck.test <- nrow(test)
  
  train$responseVar <- train[, yvar]
  total_avg_response <- mean(train$responseVar, na.rm=TRUE)  # Fixed only for this contest
  
  for (i in 1:len) {
    train$groupingVar <- train[, varList[i]]
    test$groupingVar <- test[, varList[i]]   
    
    df <- train %>%
      group_by(groupingVar) %>%
      summarise(
        freq = n() - 1,
        YRate = mean(responseVar, na.rm=TRUE)
      ) %>% ungroup()
    
    train <- left_join(train, df, by='groupingVar')
    
    train_tmp <- unique(train[, c('groupingVar', 'freq', 'YRate')])
    test <- left_join(test, train_tmp, by='groupingVar')
    names(test)[which(names(test)=='freq')] <- 'dummyFreq'
    names(test)[which(names(test)=='YRate')] <- 'dummyRate'
    test$dummyFreq <- test$dummyFreq + 1
    test$dummyFreq[is.na(test$dummyFreq)] <- 0
    
    ids <- which(is.na(test$dummyRate))
    test$dummyRate[ids] <- total_avg_response
    test$dummyRate[-ids] <- (test$dummyRate[-ids] + (total_avg_response * cred / test$dummyFreq[-ids])) * (test$dummyFreq[-ids] / (test$dummyFreq[-ids] + cred))
    
    if (freq) {
      names(test)[which(names(test)=='dummyFreq')] <- paste(varList[i], '_freq', sep='')  
    } else {
      id <- which(names(test)=='dummyFreq')
      test[, id] <- NULL
    }
    
    names(test)[which(names(test)=='dummyRate')] <- paste(varList[i], '_', yvar, 'Rate', sep='')
    
    # Leave one out adjustment for train data
    train$YRate <- (train$YRate - (train$responseVar / (train$freq+1))) * (train$freq+1)/(train$freq)
    train$YRate <- (train$YRate + (total_avg_response * cred / train$freq)) * (train$freq / (train$freq + cred))
    train$YRate[train$freq == 0] <- total_avg_response
    set.seed(10)
    train$YRate <- train$YRate * (1+(runif(nrow(train))-0.5) * rand)
    
    if (freq) {
      names(train)[which(names(train)=='freq')] <- paste(varList[i], '_freq', sep='')
    } else {
      id <- which(names(train)=='freq')
      train[, id] <- NULL
    }
    
    names(train)[which(names(train)=='YRate')] <- paste(varList[i], '_', yvar, 'Rate', sep='')
    
    train$groupingVar <- NULL;
    test$groupingVar <- NULL;
  }
  
  train$responseVar <- NULL; train$groupingVar <- NULL; test$groupingVar <- NULL;
  
  if(nrow(train) != rowNumCheck.train) print('Error: Different number of rows in train data. Bad join!')
  
  if(nrow(test) != rowNumCheck.test) print('Error: Different number of rows in test data. Bad join!')
  
  return(test)
}


```



```{r csv file}
write.csv(select(test, Id, Prediction), "preds.csv", row.names = F)

```


